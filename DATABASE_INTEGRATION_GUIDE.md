# 🗄️ Database Integration Guide

## ✅ Current Status

### **Database Schema (Simplified)**
Your Supabase `PhotoIage` table now has the following simplified structure:

```sql
PhotoIage (
  id BIGINT PRIMARY KEY,           -- Auto-incrementing ID
  created_at TIMESTAMPTZ,          -- Auto-generated timestamp
  tracking_id UUID UNIQUE,         -- Unique report identifier
  latitude REAL,                   -- GPS latitude
  longitude REAL,                  -- GPS longitude  
  category TEXT,                   -- Issue category
  description TEXT,                -- AI description
  location_address TEXT,           -- Human-readable address
  image_url TEXT,                  -- Image URL for map display
  twitter_url TEXT                 -- Social media post URL
)
```

### **Current Working Setup**
- ✅ **Frontend**: Next.js app with image upload and metadata extraction
- ✅ **Backend**: FastAPI with Groq AI analysis and in-memory storage
- ✅ **Database**: Simplified Supabase table ready for integration
- ✅ **Dependencies**: All packages installed and working

## 🔄 Current Data Flow

```
Frontend Upload → FastAPI Backend → Groq AI Analysis → 
If Valid Issue → Store in Memory (ready for DB) → Return Response
If Invalid → Reject (no storage)
```

## 🎯 For Your Teammates: Database Integration

### **1. Required Dependencies**
Add to `backend/requirements.txt`:
```
supabase>=2.3.0
postgrest>=0.13.0
```

### **2. Environment Variables**
Your `.env` file already has:
```bash
SUPABASE_URL=https://ybqelfyfhuxdmjobupxz.supabase.co
SUPABASE_SERVICE_ROLE_KEY=eyJ...
SUPABASE_TABLE_NAME=PhotoIage
```

### **3. Database Helper Usage**
Use the provided `database_helper.py`:

```python
from database_helper import DatabaseHelper

# In your main pipeline after AI analysis:
if analysis_results['category'] != "None":
    # Prepare record for database
    db_record = DatabaseHelper.prepare_record_for_database(
        tracking_id=tracking_id,
        latitude=latitude,
        longitude=longitude,
        category=analysis_results['category'],
        description=analysis_results['Text_Description'],
        image_url=f"/uploads/{processed_filename}",
        location_address=None,  # Add reverse geocoding later
        twitter_url=None  # Add after social media posting
    )
    
    # Insert into database
    # supabase_client.table("PhotoIage").insert(db_record).execute()
```

### **4. Integration Points**

#### **A. After AI Analysis (main.py line ~153)**
```python
# Current: Store in memory
reports_db[tracking_id] = response.model_dump()

# Add: Store in database
if analysis_results['category'] != "None":
    db_record = DatabaseHelper.prepare_record_for_database(...)
    # Insert to database here
```

#### **B. After Form Submission (TODO)**
```python
# Update database with form tracking number
# supabase_client.table("PhotoIage")
#   .update({"twitter_url": form_tracking_url})
#   .eq("tracking_id", tracking_id)
#   .execute()
```

#### **C. After Social Media Posting (TODO)**
```python
# Update database with social media URL
# supabase_client.table("PhotoIage")
#   .update({"twitter_url": twitter_url})
#   .eq("tracking_id", tracking_id)
#   .execute()
```

## 📋 Field Mapping

### **From AI Analysis to Database**
```python
analysis_results = {
    'category': 'Road Crack',           → category
    'Text_Description': '...',          → description  
    'Lat': 37.7749,                    → latitude
    'Long': -122.4194,                 → longitude
    'confidence': 0.87                  → (not stored in simplified schema)
}
```

### **Additional Fields to Populate**
- `tracking_id`: Generated by `DatabaseHelper.generate_tracking_id()`
- `image_url`: Path to stored image file
- `location_address`: From reverse geocoding API (optional)
- `twitter_url`: From social media posting (optional)

## 🚨 Important Notes

### **What Was Removed**
These fields were removed from the original schema:
- `ai_confidence` - AI confidence scores
- `status` - Pipeline status tracking  
- `urgency` - Urgency levels
- `is_verified` - Admin verification
- `verification_date` - Verification timestamps
- `agent_analysis` - Full AI analysis JSON
- `estimated_cost` - Cost estimates

### **Impact on Code**
- ✅ **No impact on current code** (using in-memory storage)
- ⚠️ **Future database integration** will need to remove references to deleted fields
- ✅ **Core functionality preserved** (tracking, location, categorization)

## 🧪 Testing

### **Current Tests Passing**
```bash
# Backend
cd backend
python3 -c "from main import app; print('✅ Backend OK')"

# Frontend  
cd frontend
npm run build  # ✅ Builds successfully
```

### **Database Connection Test**
```python
# Test when you add Supabase client
from database_helper import DatabaseHelper
record = DatabaseHelper.example_database_integration()
print("✅ Database helper working")
```

## 🔗 API Endpoints Ready for Database

### **Current Endpoints**
- `POST /api/submit-civic-issue` - Main upload pipeline
- `GET /api/reports/{report_id}` - Get specific report
- `GET /api/reports` - Get all reports  
- `GET /api/analytics` - Analytics data

### **Ready for Database Integration**
All endpoints currently use `reports_db` (in-memory). Simply replace with database queries:

```python
# Current: reports_db[tracking_id]
# Future: supabase.table("PhotoIage").select("*").eq("tracking_id", tracking_id)
```

## 🚀 Next Steps for Team

1. **Add Supabase client** to backend
2. **Replace in-memory storage** with database calls
3. **Test database integration** with sample uploads
4. **Add reverse geocoding** for `location_address`
5. **Integrate form submission** automation
6. **Add social media posting** functionality

## 📞 Questions?

The simplified database schema is production-ready and optimized for:
- 🗺️ **Map visualization** (latitude, longitude, image_url)
- 🔍 **Report tracking** (tracking_id, category, description)
- 📱 **Social media integration** (twitter_url)
- 📍 **Location services** (location_address)

Everything is set up for seamless integration when your teammates are ready! 🎉
